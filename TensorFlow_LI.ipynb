{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_LI",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGjqu8g+7ATHMUdKy7S5CN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somesh636/Google_Colab_Projects/blob/master/TensorFlow_LI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVqZ6WJb9NL",
        "colab_type": "code",
        "outputId": "17352ed0-35e6-4ec9-e618-e0f713f67593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yh3OzyQfN7D",
        "colab_type": "text"
      },
      "source": [
        "LINKEDIN LEARNING MODULE CHAPTER-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAvQD5Y3dydi",
        "colab_type": "code",
        "outputId": "bb6eeaa2-5a11-4197-8e79-6b28c727d29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "msg = tf.string_join(['Hello', 'TensorFlow'])\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  print(sess.run(msg))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'HelloTensorFlow'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BW8t0jiiTV0",
        "colab_type": "code",
        "outputId": "981e55a7-60da-413e-dad5-bc92721e6a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "t1 = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
        "t2 = tf.slice(t1, [1,1], [2,2])\n",
        "print(t2)\n",
        "print(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Slice:0\", shape=(2, 2), dtype=int32)\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f0b4ce85908>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdVKlq2nmNZ",
        "colab_type": "code",
        "outputId": "e2a3eb3c-0ce2-43ff-d1ec-67b636a40f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "''' usage of Tensors, Graphs, Sessions'''\n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "# Create two tensor and perform addition \n",
        "\n",
        "t1 = tf.constant([1.2, 2.3, 3.4, 4.5])\n",
        "t2 = tf.random_normal([4])\n",
        "t3 = t1+t2 \n",
        "graph1 = tf.get_default_graph()\n",
        "\n",
        "# Create second Graph and two tensors \n",
        "graph2 = tf.Graph()\n",
        "with graph2.as_default():\n",
        "  t4 = tf.constant([5.6, 6.7, 7.8, 8.9])\n",
        "  t5 = tf.random_normal([4])\n",
        "  t6 = t4 - t5 \n",
        "\n",
        "# t4 = tf.constant([5.6, 6.7, 7.8, 8.9])\n",
        "# t5 = tf.random_normal([4])\n",
        "# t6 = t4 - t5\n",
        "# graph2 = tf.get_default_graph()\n",
        "\n",
        "with tf.Session(graph=graph1) as sess:\n",
        "  print('Addition ', sess.run(t3)) \n",
        "\n",
        "with tf.Session(graph=graph2) as sess: \n",
        "  print('Substraction ', sess.run(t6))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Addition  [0.35882372 3.4875631  2.5822103  4.015149  ]\n",
            "Substraction  [ 5.370562   6.9681244  8.317058  10.597717 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxQYz7IAuB4e",
        "colab_type": "code",
        "outputId": "0b3b6f22-a6e2-4590-860c-8e92856fe772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''' TensorFlow Variable Initialization ''' \n",
        "\n",
        "v1 = tf.Variable(2)\n",
        "v2 = tf.Variable(3)\n",
        "v3 = v1 + v2 \n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(init)\n",
        "  result = sess.run(v3)\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  tf.logging.info('Result: {0}'.format(result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Result: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgAizC6wsBT-",
        "colab_type": "code",
        "outputId": "6217a82c-9724-4c26-9af9-bec2c4a0dad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "''' Tensorflow Machine Learning and Training With Optimizer '''\n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function \n",
        "import tensorflow as tf \n",
        "\n",
        "learn_rate = 0.2 \n",
        "num_steps = 100 \n",
        "\n",
        "x = tf.Variable(0.0)\n",
        "loss = tf.pow(x, 2) - 4.0*x + 5.0 \n",
        "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(loss)\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for _ in range(num_steps):\n",
        "    _, loss_val, x_val = sess.run([optimizer, loss, x])\n",
        "\n",
        "  \n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  str = 'x is {0} and the loss is {1} '.format(x_val, loss_val)\n",
        "  tf.logging.info(str)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:x is 1.9449639320373535 and the loss is 1.0032293796539307 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz1yEkNzbjDz",
        "colab_type": "code",
        "outputId": "8b091b55-1972-4a5b-ebba-b8507e14b11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbWAB02F0VX1",
        "colab_type": "code",
        "outputId": "ba99eefa-9a81-4d0d-b597-368ac9e1d6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "''' LINEAR REGRESSION ''' \n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function \n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "\n",
        "\n",
        "N =1000 \n",
        "learn_rate = 0.1\n",
        "batch_size = 40 \n",
        "num_batches = 400 \n",
        "\n",
        "x = np.random.normal(size=N)\n",
        "m_real = np.random.normal(loc=0.5, scale=0.2, size=N)\n",
        "b_real = np.random.normal(loc=1.0, scale=0.2, size=N)\n",
        "\n",
        "y = m_real*x + b_real \n",
        "m = tf.Variable(tf.random_normal([]))\n",
        "b = tf.Variable(tf.random_normal([]))\n",
        "\n",
        "gstep = tf.Variable(0, trainable=False)\n",
        "\n",
        "x_holder = tf.placeholder(tf.float32, shape=[batch_size])\n",
        "y_holder = tf.placeholder(tf.float32, shape=[batch_size])\n",
        "\n",
        "model = m * x_holder + b \n",
        "loss = tf.reduce_mean(tf.pow(model - y_holder, 2))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n",
        "\n",
        "op1 = tf.summary.scalar('m', m)\n",
        "op2 = tf.summary.scalar('b', b)\n",
        "merged_op = tf.summary.merge_all()\n",
        "\n",
        "file_writer = tf.sum\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for _ in range(num_batches): \n",
        "    x_data = np.empty(batch_size)\n",
        "    y_data = np.empty(batch_size)\n",
        "\n",
        "    for i in range(batch_size): \n",
        "      index = np.random.randint(0,N)\n",
        "      x_data[i] = x[index]\n",
        "      y_data[i] = y[index]\n",
        "\n",
        "    sess.run(optimizer, feed_dict = {x_holder: x_data, y_holder: y_data})\n",
        "  \n",
        "  print('m: ', sess.run(m))\n",
        "  print('b: ', sess.run(b))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f0e2b534cd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmerged_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'sum'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXJ8I3mJYTuo",
        "colab_type": "code",
        "outputId": "b8570a96-0c29-482f-b539-2dd741e4f57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZw8N0ejaX2J",
        "colab_type": "code",
        "outputId": "b786911c-37af-414f-b652-f8a0fdc1197e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "''' Dataset and Iterators Creation '''\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "def gen_func():\n",
        "  x = 12\n",
        "  while x < 20: \n",
        "    yield x \n",
        "    x += 2\n",
        "\n",
        "ds1 = tf.data.Dataset.range(4)\n",
        "iter1 = ds1.make_one_shot_iterator()\n",
        "\n",
        "t1 = tf.constant([4,5])\n",
        "t2 = tf.constant([6,7])\n",
        "\n",
        "ds2 = tf.data.Dataset.from_tensors([t1, t2])\n",
        "iter2 = ds2.make_one_shot_iterator()\n",
        "\n",
        "t3 = tf.constant([[8], [9], [10], [11]]) \n",
        "ds3 = tf.data.Dataset.from_tensor_slices(t3)\n",
        "iter3 = ds3.make_one_shot_iterator()\n",
        "\n",
        "ds4 = tf.data.Dataset.from_generator(gen_func, output_types=tf.int64)\n",
        "iter4 = ds4.make_one_shot_iterator()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter1.get_next()))\n",
        "\n",
        "  print(sess.run(iter2.get_next()))\n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter3.get_next()))\n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter4.get_next()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-354ceeef3a41>:15: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[[4 5]\n",
            " [6 7]]\n",
            "[8]\n",
            "[9]\n",
            "[10]\n",
            "[11]\n",
            "12\n",
            "14\n",
            "16\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeXY8n4Sa9ih",
        "colab_type": "code",
        "outputId": "3869a4bb-f0e2-48e5-91e6-aa261d911705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlzrWTojb_X2",
        "colab_type": "code",
        "outputId": "3b2b09b5-e15b-4839-ef5a-a7aafaf8ceeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "''' Working with MNIST Datasets ''' \n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "from google.colab import drive \n",
        "\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dset_path = 'https://drive.google.com/open?id=1mGMZvhmruGOan4ne9PQD4WezKukyxPA_'\n",
        "\n",
        "dset = tf.data.TFRecordDataset(dest_path)\n",
        "iter = dset.make_one_shot_iterator()\n",
        "\n",
        "feature_dict = {'images': tf.FixedLenFeature([], tf.string),\n",
        "                'labels': tf.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  example = sess.run(iter.get_next())\n",
        "  mnist = tf.parse_single_example(example, feature_dict)\n",
        "\n",
        "  pixels = tf.decode_raw(mnist['images'], tf.uint8)\n",
        "  pixel_matrix = pixels.eval().reshape((28,28))\n",
        "  plt.imshow(pixel_matrix, cmap='gray')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f4225990026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/open?id=1mGMZvhmruGOan4ne9PQD4WezKukyxPA_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dest_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT-Glo25qNwE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcFg5qUa1h5N",
        "colab_type": "code",
        "outputId": "936d6742-6e41-4deb-906b-0ca72bd44edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzWCajww1ieI",
        "colab_type": "code",
        "outputId": "1d009bd5-1538-4803-f9e3-e539bc7e2f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "''' Working with MNIST Datasets ''' \n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "from google.colab import drive \n",
        "\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#dset_path = '/content/drive/My Drive/mnist_test.tfrecords'\n",
        "\n",
        "dset = tf.data.TFRecordDataset('/content/drive/My Drive/mnist_test.tfrecords')\n",
        "iter = dset.make_one_shot_iterator()\n",
        "\n",
        "feature_dict = {'images': tf.FixedLenFeature([], tf.string),\n",
        "                'labels': tf.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  example = sess.run(iter.get_next())\n",
        "  mnist = tf.parse_single_example(example, feature_dict)\n",
        "\n",
        "  pixels = tf.decode_raw(mnist['images'], tf.uint8)\n",
        "  pixel_matrix = pixels.eval().reshape((28,28))\n",
        "  plt.imshow(pixel_matrix, cmap='gray')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagTPbGHAjAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0e5512d6-bffa-4338-e4bd-9c77520c4ceb"
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pa1ZDH9Ai8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "75cfb7c5-64a0-4a4c-c52d-ae3b795fa867"
      },
      "source": [
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "\n",
        "N = 1000 \n",
        "num_steps = 100\n",
        "\n",
        "x_train = np.random.normal(size=N)\n",
        "m = np.random.normal(loc=0.5, scale=0.2, size=N)\n",
        "b = np.random.normal(loc=1.0, scale=0.2, size=N)\n",
        "\n",
        "y_train = m*x_train+b \n",
        "\n",
        "x_col = tf.feature_column.numeric_column('x_coords')\n",
        "estimator = tf.estimator.LinearRegressor([x_col])\n",
        "\n",
        "train_input = tf.estimator.inputs.numpy_input_fn(x={'x_coords': x_train}, y = y_train,\n",
        "                                                 shuffle=True, num_epochs=num_steps)\n",
        "estimator.train(train_input)\n",
        "\n",
        "predict_input = tf.estimator.inputs.numpy_input_fn(x={'x_coords': np.array([1.0, 2.0],\n",
        "                                      dtype=np.float32)}, num_epochs=1, shuffle=False)\n",
        "\n",
        "results = estimator.predict(predict_input)\n",
        "\n",
        "for value in results: \n",
        "  print(\"Predictions: {0}\".format(value['predictions']))\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_9uz3953\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_9uz3953', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd72ab2bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_9uz3953/model.ckpt.\n",
            "INFO:tensorflow:loss = 170.79572, step = 1\n",
            "INFO:tensorflow:global_step/sec: 626.463\n",
            "INFO:tensorflow:loss = 8.275674, step = 101 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.6\n",
            "INFO:tensorflow:loss = 9.783201, step = 201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.151\n",
            "INFO:tensorflow:loss = 11.278259, step = 301 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.242\n",
            "INFO:tensorflow:loss = 8.852352, step = 401 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.469\n",
            "INFO:tensorflow:loss = 8.69501, step = 501 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.957\n",
            "INFO:tensorflow:loss = 9.704848, step = 601 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.32\n",
            "INFO:tensorflow:loss = 9.196251, step = 701 (0.140 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 782 into /tmp/tmp_9uz3953/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.9237491.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_9uz3953/model.ckpt-782\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Predictions: [1.523777]\n",
            "Predictions: [2.0418906]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQsJqJKOEDFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4ab2177-4a12-4846-cad3-23e6a6195db9"
      },
      "source": [
        "\"\"\" DNN Classifiers with MNIST Dataset \"\"\" \n",
        "%tensorflow_version 1.8.0 \n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function \n",
        "import tensorflow as tf \n",
        "\n",
        "image_dim = 28 \n",
        "num_labels = 10 \n",
        "batch_size = 80\n",
        "num_steps = 8000 \n",
        "hidden_layers = [128, 32]\n",
        "\n",
        "# Parser function for the MNIST data \n",
        "def parser(record): \n",
        "  features = tf.parse_single_example(record,\n",
        "            features = {'images': tf.FixedLenFeature([], tf.string),\n",
        "                        'labels': tf.FixedLenFeature([], tf.int64),})\n",
        "  image = tf.decode_raw(features['images'], tf.uint8)\n",
        "  image.set_shape([image_dim * image_dim])\n",
        "  image = tf.cast(image, tf.float32) * (1.0/255) - 0.5\n",
        "  label = features['labels']\n",
        "  return image, label\n",
        "\n",
        "column = tf.feature_column.numeric_column('pixels', shape=[image_dim * image_dim])\n",
        "\n",
        "dnn_class = tf.estimator.DNNClassifier(hidden_layers, [column],\n",
        "                  model_dir = 'dnn_output', n_classes=num_labels )\n",
        "\n",
        "def train_func():\n",
        "  dataset = tf.data.TFRecordDataset('/content/drive/My Drive/MNIST_DATASET/mnist_train.tfrecords')\n",
        "  dataset = dataset.map(parser).repeat().batch(batch_size)\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "  return {'pixels': image}, label\n",
        "\n",
        "dnn_class.train(train_func, steps=num_steps)\n",
        "\n",
        "def test_func(): \n",
        "  dataset = tf.data.TFRecordDataset('/content/drive/My Drive/MNIST_DATASET/mnist_test.tfrecords')\n",
        "  dataset = dataset.map(parser).batch(batch_size)\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "  return {'pixels': image}, label \n",
        "\n",
        "metrics = dnn_class.evaluate(test_func)\n",
        "\n",
        "for key, value in metrics.items(): \n",
        "  print(key, ': ', value)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'dnn_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd72a7a02b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Entity <function parser at 0x7fd72a803378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function parser at 0x7fd72a803378> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7fd72a74e1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7fd72a74e1d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into dnn_output/model.ckpt.\n",
            "INFO:tensorflow:loss = 196.04504, step = 1\n",
            "INFO:tensorflow:global_step/sec: 104.218\n",
            "INFO:tensorflow:loss = 78.02752, step = 101 (0.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 120.096\n",
            "INFO:tensorflow:loss = 44.719707, step = 201 (0.833 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.402\n",
            "INFO:tensorflow:loss = 38.592308, step = 301 (0.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.601\n",
            "INFO:tensorflow:loss = 30.608763, step = 401 (0.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.359\n",
            "INFO:tensorflow:loss = 36.61431, step = 501 (0.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 126.027\n",
            "INFO:tensorflow:loss = 29.98104, step = 601 (0.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.592\n",
            "INFO:tensorflow:loss = 12.410112, step = 701 (0.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.717\n",
            "INFO:tensorflow:loss = 26.88551, step = 801 (0.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.993\n",
            "INFO:tensorflow:loss = 12.100706, step = 901 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.812\n",
            "INFO:tensorflow:loss = 25.72934, step = 1001 (0.776 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.498\n",
            "INFO:tensorflow:loss = 16.054989, step = 1101 (0.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.046\n",
            "INFO:tensorflow:loss = 22.375158, step = 1201 (0.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.145\n",
            "INFO:tensorflow:loss = 19.102722, step = 1301 (0.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.426\n",
            "INFO:tensorflow:loss = 31.185795, step = 1401 (0.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.3\n",
            "INFO:tensorflow:loss = 21.034025, step = 1501 (0.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.739\n",
            "INFO:tensorflow:loss = 16.878088, step = 1601 (0.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.379\n",
            "INFO:tensorflow:loss = 13.226385, step = 1701 (0.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.217\n",
            "INFO:tensorflow:loss = 10.916574, step = 1801 (0.780 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.013\n",
            "INFO:tensorflow:loss = 16.852999, step = 1901 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.377\n",
            "INFO:tensorflow:loss = 14.608463, step = 2001 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.676\n",
            "INFO:tensorflow:loss = 7.42693, step = 2101 (0.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.865\n",
            "INFO:tensorflow:loss = 24.63469, step = 2201 (0.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 126.719\n",
            "INFO:tensorflow:loss = 12.008273, step = 2301 (0.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.965\n",
            "INFO:tensorflow:loss = 13.383465, step = 2401 (0.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.211\n",
            "INFO:tensorflow:loss = 10.014668, step = 2501 (0.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.549\n",
            "INFO:tensorflow:loss = 11.931118, step = 2601 (0.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.49\n",
            "INFO:tensorflow:loss = 9.421843, step = 2701 (0.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.976\n",
            "INFO:tensorflow:loss = 8.161121, step = 2801 (0.775 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.228\n",
            "INFO:tensorflow:loss = 13.023212, step = 2901 (0.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.957\n",
            "INFO:tensorflow:loss = 4.6512976, step = 3001 (0.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.788\n",
            "INFO:tensorflow:loss = 11.6084795, step = 3101 (0.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.977\n",
            "INFO:tensorflow:loss = 15.928389, step = 3201 (0.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.159\n",
            "INFO:tensorflow:loss = 32.49193, step = 3301 (0.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.485\n",
            "INFO:tensorflow:loss = 11.331627, step = 3401 (0.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.847\n",
            "INFO:tensorflow:loss = 10.881774, step = 3501 (0.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.221\n",
            "INFO:tensorflow:loss = 15.101746, step = 3601 (0.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.692\n",
            "INFO:tensorflow:loss = 5.302403, step = 3701 (0.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 135.367\n",
            "INFO:tensorflow:loss = 13.824723, step = 3801 (0.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.671\n",
            "INFO:tensorflow:loss = 13.276142, step = 3901 (0.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.231\n",
            "INFO:tensorflow:loss = 9.42468, step = 4001 (0.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.037\n",
            "INFO:tensorflow:loss = 11.645785, step = 4101 (0.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.455\n",
            "INFO:tensorflow:loss = 13.001582, step = 4201 (0.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.811\n",
            "INFO:tensorflow:loss = 20.025764, step = 4301 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.074\n",
            "INFO:tensorflow:loss = 5.6146297, step = 4401 (0.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.594\n",
            "INFO:tensorflow:loss = 10.796974, step = 4501 (0.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.897\n",
            "INFO:tensorflow:loss = 8.415193, step = 4601 (0.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.539\n",
            "INFO:tensorflow:loss = 7.234233, step = 4701 (0.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.047\n",
            "INFO:tensorflow:loss = 0.70308983, step = 4801 (0.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.619\n",
            "INFO:tensorflow:loss = 9.558747, step = 4901 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.306\n",
            "INFO:tensorflow:loss = 13.903124, step = 5001 (0.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.054\n",
            "INFO:tensorflow:loss = 2.1657376, step = 5101 (0.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.996\n",
            "INFO:tensorflow:loss = 15.731686, step = 5201 (0.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.462\n",
            "INFO:tensorflow:loss = 4.8578176, step = 5301 (0.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.704\n",
            "INFO:tensorflow:loss = 8.224269, step = 5401 (0.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.399\n",
            "INFO:tensorflow:loss = 12.871197, step = 5501 (0.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.188\n",
            "INFO:tensorflow:loss = 19.23104, step = 5601 (0.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.745\n",
            "INFO:tensorflow:loss = 23.173748, step = 5701 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.814\n",
            "INFO:tensorflow:loss = 11.74077, step = 5801 (0.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.415\n",
            "INFO:tensorflow:loss = 16.46152, step = 5901 (0.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.322\n",
            "INFO:tensorflow:loss = 15.299092, step = 6001 (0.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.76\n",
            "INFO:tensorflow:loss = 11.36853, step = 6101 (0.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.207\n",
            "INFO:tensorflow:loss = 6.224668, step = 6201 (0.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.318\n",
            "INFO:tensorflow:loss = 12.543616, step = 6301 (0.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.696\n",
            "INFO:tensorflow:loss = 8.846081, step = 6401 (0.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.667\n",
            "INFO:tensorflow:loss = 11.235247, step = 6501 (0.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.613\n",
            "INFO:tensorflow:loss = 4.44936, step = 6601 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.98\n",
            "INFO:tensorflow:loss = 13.876094, step = 6701 (0.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.691\n",
            "INFO:tensorflow:loss = 6.1841383, step = 6801 (0.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.354\n",
            "INFO:tensorflow:loss = 19.104105, step = 6901 (0.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.446\n",
            "INFO:tensorflow:loss = 16.150923, step = 7001 (0.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.172\n",
            "INFO:tensorflow:loss = 5.831968, step = 7101 (0.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.375\n",
            "INFO:tensorflow:loss = 8.356214, step = 7201 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.163\n",
            "INFO:tensorflow:loss = 5.1175613, step = 7301 (0.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.456\n",
            "INFO:tensorflow:loss = 9.276123, step = 7401 (0.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.894\n",
            "INFO:tensorflow:loss = 10.480793, step = 7501 (0.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.172\n",
            "INFO:tensorflow:loss = 3.6473508, step = 7601 (0.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.654\n",
            "INFO:tensorflow:loss = 14.732067, step = 7701 (0.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.955\n",
            "INFO:tensorflow:loss = 7.2747955, step = 7801 (0.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.363\n",
            "INFO:tensorflow:loss = 8.313175, step = 7901 (0.749 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into dnn_output/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 15.776365.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7fd72a5bb940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7fd72a5bb940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-05-09T20:57:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from dnn_output/model.ckpt-8000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-05-09-20:57:24\n",
            "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.9554, average_loss = 0.14270988, global_step = 8000, loss = 11.41679\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: dnn_output/model.ckpt-8000\n",
            "accuracy :  0.9554\n",
            "average_loss :  0.14270988\n",
            "loss :  11.41679\n",
            "global_step :  8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W56dqFDkN6Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}