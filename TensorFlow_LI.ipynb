{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_LI",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNL2Hn8zCV6Y08zZizYz+Xu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somesh636/Google_Colab_Projects/blob/master/TensorFlow_LI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVqZ6WJb9NL",
        "colab_type": "code",
        "outputId": "17352ed0-35e6-4ec9-e618-e0f713f67593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yh3OzyQfN7D",
        "colab_type": "text"
      },
      "source": [
        "LINKEDIN LEARNING MODULE CHAPTER-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAvQD5Y3dydi",
        "colab_type": "code",
        "outputId": "bb6eeaa2-5a11-4197-8e79-6b28c727d29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "msg = tf.string_join(['Hello', 'TensorFlow'])\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  print(sess.run(msg))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'HelloTensorFlow'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BW8t0jiiTV0",
        "colab_type": "code",
        "outputId": "981e55a7-60da-413e-dad5-bc92721e6a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "t1 = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
        "t2 = tf.slice(t1, [1,1], [2,2])\n",
        "print(t2)\n",
        "print(tf.get_default_graph())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Slice:0\", shape=(2, 2), dtype=int32)\n",
            "<tensorflow.python.framework.ops.Graph object at 0x7f0b4ce85908>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdVKlq2nmNZ",
        "colab_type": "code",
        "outputId": "e2a3eb3c-0ce2-43ff-d1ec-67b636a40f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "''' usage of Tensors, Graphs, Sessions'''\n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "# Create two tensor and perform addition \n",
        "\n",
        "t1 = tf.constant([1.2, 2.3, 3.4, 4.5])\n",
        "t2 = tf.random_normal([4])\n",
        "t3 = t1+t2 \n",
        "graph1 = tf.get_default_graph()\n",
        "\n",
        "# Create second Graph and two tensors \n",
        "graph2 = tf.Graph()\n",
        "with graph2.as_default():\n",
        "  t4 = tf.constant([5.6, 6.7, 7.8, 8.9])\n",
        "  t5 = tf.random_normal([4])\n",
        "  t6 = t4 - t5 \n",
        "\n",
        "# t4 = tf.constant([5.6, 6.7, 7.8, 8.9])\n",
        "# t5 = tf.random_normal([4])\n",
        "# t6 = t4 - t5\n",
        "# graph2 = tf.get_default_graph()\n",
        "\n",
        "with tf.Session(graph=graph1) as sess:\n",
        "  print('Addition ', sess.run(t3)) \n",
        "\n",
        "with tf.Session(graph=graph2) as sess: \n",
        "  print('Substraction ', sess.run(t6))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Addition  [0.35882372 3.4875631  2.5822103  4.015149  ]\n",
            "Substraction  [ 5.370562   6.9681244  8.317058  10.597717 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxQYz7IAuB4e",
        "colab_type": "code",
        "outputId": "0b3b6f22-a6e2-4590-860c-8e92856fe772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''' TensorFlow Variable Initialization ''' \n",
        "\n",
        "v1 = tf.Variable(2)\n",
        "v2 = tf.Variable(3)\n",
        "v3 = v1 + v2 \n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(init)\n",
        "  result = sess.run(v3)\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  tf.logging.info('Result: {0}'.format(result))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Result: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgAizC6wsBT-",
        "colab_type": "code",
        "outputId": "6217a82c-9724-4c26-9af9-bec2c4a0dad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "''' Tensorflow Machine Learning and Training With Optimizer '''\n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function \n",
        "import tensorflow as tf \n",
        "\n",
        "learn_rate = 0.2 \n",
        "num_steps = 100 \n",
        "\n",
        "x = tf.Variable(0.0)\n",
        "loss = tf.pow(x, 2) - 4.0*x + 5.0 \n",
        "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(loss)\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for _ in range(num_steps):\n",
        "    _, loss_val, x_val = sess.run([optimizer, loss, x])\n",
        "\n",
        "  \n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  str = 'x is {0} and the loss is {1} '.format(x_val, loss_val)\n",
        "  tf.logging.info(str)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:x is 1.9449639320373535 and the loss is 1.0032293796539307 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz1yEkNzbjDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8b091b55-1972-4a5b-ebba-b8507e14b11c"
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbWAB02F0VX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "ba99eefa-9a81-4d0d-b597-368ac9e1d6c5"
      },
      "source": [
        "''' LINEAR REGRESSION ''' \n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function \n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "\n",
        "\n",
        "N =1000 \n",
        "learn_rate = 0.1\n",
        "batch_size = 40 \n",
        "num_batches = 400 \n",
        "\n",
        "x = np.random.normal(size=N)\n",
        "m_real = np.random.normal(loc=0.5, scale=0.2, size=N)\n",
        "b_real = np.random.normal(loc=1.0, scale=0.2, size=N)\n",
        "\n",
        "y = m_real*x + b_real \n",
        "m = tf.Variable(tf.random_normal([]))\n",
        "b = tf.Variable(tf.random_normal([]))\n",
        "\n",
        "gstep = tf.Variable(0, trainable=False)\n",
        "\n",
        "x_holder = tf.placeholder(tf.float32, shape=[batch_size])\n",
        "y_holder = tf.placeholder(tf.float32, shape=[batch_size])\n",
        "\n",
        "model = m * x_holder + b \n",
        "loss = tf.reduce_mean(tf.pow(model - y_holder, 2))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n",
        "\n",
        "op1 = tf.summary.scalar('m', m)\n",
        "op2 = tf.summary.scalar('b', b)\n",
        "merged_op = tf.summary.merge_all()\n",
        "\n",
        "file_writer = tf.sum\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for _ in range(num_batches): \n",
        "    x_data = np.empty(batch_size)\n",
        "    y_data = np.empty(batch_size)\n",
        "\n",
        "    for i in range(batch_size): \n",
        "      index = np.random.randint(0,N)\n",
        "      x_data[i] = x[index]\n",
        "      y_data[i] = y[index]\n",
        "\n",
        "    sess.run(optimizer, feed_dict = {x_holder: x_data, y_holder: y_data})\n",
        "  \n",
        "  print('m: ', sess.run(m))\n",
        "  print('b: ', sess.run(b))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f0e2b534cd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmerged_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'sum'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXJ8I3mJYTuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b8570a96-0c29-482f-b539-2dd741e4f57f"
      },
      "source": [
        "%tensorflow_version 1.8"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZw8N0ejaX2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "b786911c-37af-414f-b652-f8a0fdc1197e"
      },
      "source": [
        "''' Dataset and Iterators Creation '''\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "def gen_func():\n",
        "  x = 12\n",
        "  while x < 20: \n",
        "    yield x \n",
        "    x += 2\n",
        "\n",
        "ds1 = tf.data.Dataset.range(4)\n",
        "iter1 = ds1.make_one_shot_iterator()\n",
        "\n",
        "t1 = tf.constant([4,5])\n",
        "t2 = tf.constant([6,7])\n",
        "\n",
        "ds2 = tf.data.Dataset.from_tensors([t1, t2])\n",
        "iter2 = ds2.make_one_shot_iterator()\n",
        "\n",
        "t3 = tf.constant([[8], [9], [10], [11]]) \n",
        "ds3 = tf.data.Dataset.from_tensor_slices(t3)\n",
        "iter3 = ds3.make_one_shot_iterator()\n",
        "\n",
        "ds4 = tf.data.Dataset.from_generator(gen_func, output_types=tf.int64)\n",
        "iter4 = ds4.make_one_shot_iterator()\n",
        "\n",
        "with tf.Session() as sess: \n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter1.get_next()))\n",
        "\n",
        "  print(sess.run(iter2.get_next()))\n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter3.get_next()))\n",
        "\n",
        "  for _ in range(4):\n",
        "    print(sess.run(iter4.get_next()))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-354ceeef3a41>:15: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[[4 5]\n",
            " [6 7]]\n",
            "[8]\n",
            "[9]\n",
            "[10]\n",
            "[11]\n",
            "12\n",
            "14\n",
            "16\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeXY8n4Sa9ih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3869a4bb-f0e2-48e5-91e6-aa261d911705"
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlzrWTojb_X2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "3b2b09b5-e15b-4839-ef5a-a7aafaf8ceeb"
      },
      "source": [
        "''' Working with MNIST Datasets ''' \n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "from google.colab import drive \n",
        "\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dset_path = 'https://drive.google.com/open?id=1mGMZvhmruGOan4ne9PQD4WezKukyxPA_'\n",
        "\n",
        "dset = tf.data.TFRecordDataset(dest_path)\n",
        "iter = dset.make_one_shot_iterator()\n",
        "\n",
        "feature_dict = {'images': tf.FixedLenFeature([], tf.string),\n",
        "                'labels': tf.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  example = sess.run(iter.get_next())\n",
        "  mnist = tf.parse_single_example(example, feature_dict)\n",
        "\n",
        "  pixels = tf.decode_raw(mnist['images'], tf.uint8)\n",
        "  pixel_matrix = pixels.eval().reshape((28,28))\n",
        "  plt.imshow(pixel_matrix, cmap='gray')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f4225990026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/open?id=1mGMZvhmruGOan4ne9PQD4WezKukyxPA_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dest_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT-Glo25qNwE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcFg5qUa1h5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "936d6742-6e41-4deb-906b-0ca72bd44edb"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzWCajww1ieI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1d009bd5-1538-4803-f9e3-e539bc7e2f73"
      },
      "source": [
        "''' Working with MNIST Datasets ''' \n",
        "\n",
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "from google.colab import drive \n",
        "\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#dset_path = '/content/drive/My Drive/mnist_test.tfrecords'\n",
        "\n",
        "dset = tf.data.TFRecordDataset('/content/drive/My Drive/mnist_test.tfrecords')\n",
        "iter = dset.make_one_shot_iterator()\n",
        "\n",
        "feature_dict = {'images': tf.FixedLenFeature([], tf.string),\n",
        "                'labels': tf.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "with tf.Session() as sess: \n",
        "  example = sess.run(iter.get_next())\n",
        "  mnist = tf.parse_single_example(example, feature_dict)\n",
        "\n",
        "  pixels = tf.decode_raw(mnist['images'], tf.uint8)\n",
        "  pixel_matrix = pixels.eval().reshape((28,28))\n",
        "  plt.imshow(pixel_matrix, cmap='gray')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}